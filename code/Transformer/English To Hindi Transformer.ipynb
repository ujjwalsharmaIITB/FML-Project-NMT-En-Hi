{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# from datasets import load_dataset\n",
        "\n",
        "# dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
        "\n",
        "\n",
        "# with open('eng-hin-train.txt' , 'w+' , encoding = \"utf8\") as file:\n",
        "#     file.write(\"ENGLISH_SENTENCE_sep_HINDI_SENTENCE\")\n",
        "#     file.write(\"\\n\")\n",
        "#     for translation_pair in dataset[\"train\"][\"translation\"]:\n",
        "#         source_sentence = translation_pair[\"en\"]\n",
        "#         target_sentence = translation_pair[\"hi\"]\n",
        "#         file.write(source_sentence.strip() + \"_sep_\")\n",
        "#         file.write(target_sentence.strip() + \"\\n\")"
      ],
      "metadata": {
        "id": "rj0Bb7DzvUnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://storage.googleapis.com/drive-bulk-export-anonymous/20231127T081635.493Z/4133399871716478688/f4c6d602-f7e9-4be8-b29c-0ab031d52074/1/2d45123d-fab0-403e-b62d-be0ca5b37baa?authuser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-5DQkE-2V7N",
        "outputId": "9c6831b0-0d50-4f5d-f445-b2bb916a8c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 08:18:36--  https://storage.googleapis.com/drive-bulk-export-anonymous/20231127T081635.493Z/4133399871716478688/f4c6d602-f7e9-4be8-b29c-0ab031d52074/1/2d45123d-fab0-403e-b62d-be0ca5b37baa?authuser\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 74.125.137.207, 142.250.101.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18045628 (17M) [application/x-zip]\n",
            "Saving to: ‘2d45123d-fab0-403e-b62d-be0ca5b37baa?authuser’\n",
            "\n",
            "2d45123d-fab0-403e- 100%[===================>]  17.21M  46.3MB/s    in 0.4s    \n",
            "\n",
            "2023-11-27 08:18:37 (46.3 MB/s) - ‘2d45123d-fab0-403e-b62d-be0ca5b37baa?authuser’ saved [18045628/18045628]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip test.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO5olNs_2rLA",
        "outputId": "d11eb5d3-c3fd-408c-9124-708c94566622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test.zip\n",
            "  inflating: eng-hin-train-200000.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ro3GJZHPNc"
      },
      "source": [
        "**Data loading and Preprocessing**\n",
        "\n",
        "\n",
        "*   We will load all the files directly from the Google drive. So first we have to mount the drive into collab notebook.\n",
        "\n",
        "*   For preprocessing we will only use csv module of python.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91gV0HOvHlk_"
      },
      "source": [
        "import csv\n",
        "import string\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#setting the device to \"cuda\" if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-A3R5Z_Jr-B"
      },
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "For data preprocessing, we will do following steps:\n",
        "\n",
        "1. Do not process sentences whose length is less than the MAX_LENGTH\n",
        "2. Do not process any null pair\n",
        "3. Converting into lowercase characters\n",
        "4. Removing all punctutations from the sentences.\n",
        "5. Removing the sentences who have some \"english\" words in hindi sentences.\n",
        "6. Change the encoding of the sentences.\n",
        "7. Build vocabulary for hindi and english languages to map index to unique words and vice versa.\n",
        "8. Converting sentence into tensors for further processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP08NGsyJq41"
      },
      "source": [
        "MAX_LENGTH=20\n",
        "\n",
        "class Vocab_builder:\n",
        "    def __init__(self):\n",
        "        self.word_2_index={\"<SOS>\":0,\"<EOS>\":1,\"<PAD>\":2,\"<UKN>\":3}\n",
        "        self.index_2_word={0:\"<SOS>\", 1:\"<EOS>\", 2:\"<PAD>\", 3:\"<UKN>\"}\n",
        "        self.freq={}\n",
        "        self.size=4\n",
        "\n",
        "    def add_this_sentence(self,sentence):\n",
        "        words=sentence.split(\" \")\n",
        "        for word in words:\n",
        "            if word not in self.word_2_index:\n",
        "                #If the word is not there, add it to a new index and store the indexes\n",
        "                #Initialize the frequency of the word to 1 and increase the size of the vocabulary\n",
        "                self.word_2_index[word]=self.size\n",
        "                self.freq[word]=1\n",
        "                self.index_2_word[self.size]=word\n",
        "                self.size+=1\n",
        "            else:\n",
        "                # If the word is already present then just increase the frequency\n",
        "                self.freq[word]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1W9XJWMCzv"
      },
      "source": [
        "#Initilizing the objects of hindi and english vocabularies:\n",
        "hindi_vocab=Vocab_builder()\n",
        "eng_vocab=Vocab_builder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KfIQgM8MRGK"
      },
      "source": [
        "def length(sentence):\n",
        "    '''\n",
        "        Function to tell the length of a sentence.\n",
        "    '''\n",
        "    return len(sentence.split(\" \"))\n",
        "\n",
        "def is_mixed(sentence):\n",
        "    '''\n",
        "        This function will return True if a hindi sentence is containing some english character.\n",
        "    '''\n",
        "    letters=\"abcdefghijklmnopqrstuvwxyz\"\n",
        "    for ch in letters:\n",
        "        if ch in sentence:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def preprocess(sentence):\n",
        "    '''\n",
        "        This function will apply the neccesary preprocessing to a sentence\n",
        "    '''\n",
        "    #First we will remove all punctuations from the sentence\n",
        "    punctuations=list(string.punctuation)\n",
        "    cleaned=\"\"\n",
        "    for letter in sentence:\n",
        "        if letter not in punctuations:\n",
        "            cleaned+=letter\n",
        "    cleaned=cleaned.lower() ## Converting into lowercase\n",
        "    return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtBpfbg8IbkE"
      },
      "source": [
        "def clean_the_data(path):\n",
        "    '''\n",
        "      This function will load the data and process it line by line.\n",
        "      It will apply all the preprocessing and make the data ready for further processing.\n",
        "    '''\n",
        "    pairs=[]\n",
        "    with open(path,'rt') as f:\n",
        "        data=f.readlines()\n",
        "        row_num=0\n",
        "        for row in data:\n",
        "            if row_num!=0:  #We will not process first row as it will contain header\n",
        "                unfiltered_sentences = row.split(\"_sep_\")\n",
        "                hindi=unfiltered_sentences[1]\n",
        "                eng=unfiltered_sentences[0]\n",
        "\n",
        "                if length(hindi)>=MAX_LENGTH or length(eng)>=MAX_LENGTH:  #skipping if length is more than MAX_LENGTH\n",
        "                    continue\n",
        "                if not hindi or not eng:  #skipping pair having any NULL value\n",
        "                    continue\n",
        "                if is_mixed(hindi):   #skipping sentence if it contains some english word\n",
        "                    continue\n",
        "                hindi=hindi.encode('utf-8',errors='ignore').decode('utf-8')\n",
        "                eng=eng.encode('ascii',errors='ignore').decode('utf-8')\n",
        "                hindi=preprocess(hindi)\n",
        "                eng=preprocess(eng)\n",
        "                #Adding <SOS>, <EOS> and padding tokens\n",
        "                pair=[hindi.strip(), eng.strip()]\n",
        "\n",
        "                hin_extra=MAX_LENGTH-len(hindi.strip().split(\" \"))\n",
        "                eng_extra=MAX_LENGTH-len(eng.strip().split(\" \"))\n",
        "\n",
        "                hindi_vocab.add_this_sentence(pair[0])\n",
        "                eng_vocab.add_this_sentence(pair[1])\n",
        "                pair[0]=pair[0].split(\" \")\n",
        "                pair[0].insert(0,\"<SOS>\")\n",
        "                pair[0].append(\"<EOS>\")\n",
        "                pair[0]=pair[0]+[\"<PAD>\"]*(hin_extra)\n",
        "\n",
        "                pair[1]=pair[1].split(\" \")\n",
        "                pair[1].insert(0,\"<SOS>\")\n",
        "                pair[1].append(\"<EOS>\")\n",
        "                pair[1]=pair[1]+[\"<PAD>\"]*(eng_extra)\n",
        "\n",
        "                pair[0]=\" \".join(pair[0])\n",
        "                pair[1]=\" \".join(pair[1])\n",
        "                pairs.append(pair)\n",
        "            row_num+=1\n",
        "    return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If_qHw3iI0Zj"
      },
      "source": [
        "train_file_path=\"eng-hin-train-200000.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQD3qXWeYF93"
      },
      "source": [
        "pairs=clean_the_data(train_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfjYSISX7LPD",
        "outputId": "d017f109-676f-4040-af5d-7ba82ae2be8b"
      },
      "source": [
        "print(pairs[11])\n",
        "print(len(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<SOS> छींटा <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', '<SOS> pitterpatter <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>']\n",
            "135864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxzf6b1uYRLH"
      },
      "source": [
        "#Now we need to convert each of this pair into corresponding tensors\n",
        "def pair_to_tensor(pair):\n",
        "    '''\n",
        "    A function to convert a given pair to tensors corresponding to index in vocabulary\n",
        "    '''\n",
        "    hindi_sentence=pair[0]\n",
        "    eng_sentence=pair[1]\n",
        "    indexes_hindi=[hindi_vocab.word_2_index[word] for word in hindi_sentence.split(' ')]\n",
        "    indexes_eng=[eng_vocab.word_2_index[word] for word in eng_sentence.split(' ')]\n",
        "    hindi_tensor=torch.tensor(indexes_hindi, dtype=torch.long, device=device).view(-1,1)\n",
        "    eng_tensor=torch.tensor(indexes_eng, dtype=torch.long, device=device).view(-1,1)\n",
        "    return (hindi_tensor, eng_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6erfJEZYVFv"
      },
      "source": [
        "hin_tensors=[]\n",
        "eng_tensors=[]\n",
        "for pair in pairs:      # we will convert each pair into tensor to process it\n",
        "    hin,eng=pair_to_tensor(pair)\n",
        "    hin_tensors.append(hin)\n",
        "    eng_tensors.append(eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqFysuNLVXDr"
      },
      "source": [
        "**Transformers**\n",
        "\n",
        "References:\n",
        "1. https://arxiv.org/abs/1706.03762\n",
        "2. https://www.youtube.com/watch?v=iDulhoQ2pro\n",
        "3. https://www.youtube.com/watch?v=TQQlZhbC5ps&t=636s\n",
        "4. https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OPzyQrDVUlZ"
      },
      "source": [
        "class Transformer_model(nn.Module):\n",
        "    def __init__(self, embed_size, len_src_vocab, len_tgt_vocab, src_pad_index, num_heads, enc_layers, dec_layers, forward_exp, dropout, max_length,device):\n",
        "        super(Transformer_model,self).__init__()\n",
        "        self.src_word_embedding=nn.Embedding(len_src_vocab, embed_size) #shape: (len_src_vocab, embed_size)\n",
        "        self.tgt_word_embedding=nn.Embedding(len_tgt_vocab, embed_size) #shape: (len_eng_vocab, embed_size)\n",
        "        self.src_positional_embedding=nn.Embedding(max_length, embed_size) #shape: (MAX_LENGTH, embed_size)\n",
        "        self.tgt_positional_embedding=nn.Embedding(max_length, embed_size)  #shape: (MAX_LENGTH, embed_size)\n",
        "        self.device=device\n",
        "        self.transformer_layer=nn.Transformer(embed_size, num_heads,enc_layers, dec_layers, forward_expansion, dropout)\n",
        "        self.out_fc=nn.Linear(embed_size, len_tgt_vocab)    #linear layer to predicted the output word\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.src_pad_index=src_pad_index\n",
        "\n",
        "    def gen_mask_for_src(self, source):\n",
        "        #need to transpose source as padding need to be of size (batch_size, seq_len) but source is of shape (seq_len, batch_size)\n",
        "        source=source.transpose(0,1)\n",
        "        mask=(source==self.src_pad_index) #(mask will contain 1 where there is pad token, and 0 otherwise)\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, target):\n",
        "        src_seq_length, batch_size=src.shape\n",
        "        tgt_seq_length, batch_size=target.shape\n",
        "        # creating positional embeddings to encode position of words in transformer (it will be just a range array upto max_length)\n",
        "        src_positional=torch.arange(0,src_seq_length).unsqueeze(1).expand(src_seq_length, batch_size).to(self.device)\n",
        "        tgt_positional=torch.arange(0,tgt_seq_length).unsqueeze(1).expand(tgt_seq_length, batch_size).to(self.device)\n",
        "        # calculating embeddings as sum of positional and word embeddings\n",
        "        src_embedding=self.dropout(self.src_word_embedding(src)+self.src_positional_embedding(src_positional))\n",
        "        tht_embedding=self.dropout(self.tgt_word_embedding(target)+self.tgt_positional_embedding(tgt_positional))\n",
        "        # generating padding mask for hindi (source)\n",
        "        src_padding_mask=self.gen_mask_for_src(src)\n",
        "        # using in-built transformer function to generate mask for english (target)\n",
        "        # It will be in form of a lower-triangular matrix\n",
        "        tgt_mask=self.transformer_layer.generate_square_subsequent_mask(tgt_seq_length).to(self.device)\n",
        "        output=self.transformer_layer(src_embedding, tht_embedding, src_key_padding_mask=src_padding_mask, tgt_mask=tgt_mask)\n",
        "        output=self.out_fc(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh0WtJgzeK1x"
      },
      "source": [
        "**Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcOY4wESkGpG"
      },
      "source": [
        "# defining model parameters\n",
        "embed_size=512\n",
        "len_hin_vocab=hindi_vocab.size\n",
        "len_eng_vocab=eng_vocab.size\n",
        "padding_idx=eng_vocab.word_2_index[\"<PAD>\"]\n",
        "num_heads=8\n",
        "enc_layers, dec_layers= 1,1\n",
        "dropout=0.10\n",
        "forward_expansion=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0azI1NkDoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f11eb1-f312-4683-9569-2bfa5b67dbf3"
      },
      "source": [
        "model=Transformer_model(embed_size, len_eng_vocab, len_hin_vocab, padding_idx, num_heads, enc_layers, dec_layers, forward_expansion, dropout, MAX_LENGTH+2,device).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQ7lB6dsPgf"
      },
      "source": [
        "model_available=False # A variable to indicate whether a model is present in the path or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "VW2h975empIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRrEbs8HeIXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40871acb-3227-422c-b3c5-cb42dee8c516"
      },
      "source": [
        "import time\n",
        "batch_size=128\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
        "PATH=\"model.pth\"\n",
        "\n",
        "epochs=20\n",
        "epoch_loss=0.0\n",
        "\n",
        "criterion=nn.CrossEntropyLoss(ignore_index=padding_idx) #ignore padding index while calculating loss\n",
        "\n",
        "\n",
        "if model_available:\n",
        "    model=torch.load(PATH)\n",
        "batches=len(pairs)//batch_size\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "    print(f\"epoch {epoch+1}/{epochs}\")\n",
        "    model.eval()\n",
        "    model.train(True)\n",
        "    cur_batch=0\n",
        "    batch_start = time.time()\n",
        "    for idx in range(0,len(pairs),batch_size):\n",
        "        # will do processing for each batch\n",
        "        cur_batch+=1\n",
        "        if(cur_batch%100==0):\n",
        "            print(f\"    running batch {cur_batch} of {batches}\")\n",
        "        if idx+batch_size < len(pairs):\n",
        "            src_batch=eng_tensors[idx:idx+batch_size]\n",
        "            target_batch=hin_tensors[idx:idx+batch_size]\n",
        "        else:\n",
        "            src_batch=eng_tensors[idx:]\n",
        "            target_batch=hin_tensors[idx:]\n",
        "\n",
        "        src_batch=torch.cat(src_batch,dim=1).to(device)    #shape: (max_lenbatch_size)\n",
        "        target_batch=torch.cat(target_batch,dim=1).to(device) #shape: (max_lenbatch_size)\n",
        "        output=model(src_batch,target_batch[:-1,:])\n",
        "        output=output.reshape(-1, output.shape[2])\n",
        "\n",
        "        target=target_batch[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss=criterion(output,target)\n",
        "\n",
        "        loss.backward()\n",
        "        # restrict gradients from exploding\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print('%s (%d %d%%) %.4f' % (timeSince(start_time, (epoch+1) / epochs),\n",
        "                                        epoch+1, (epoch+1) / epochs * 100, loss.item()))\n",
        "\n",
        "    torch.save(model,PATH)\n",
        "    model_available=True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "4m 45s (- 90m 15s) (1 5%) 6.5670\n",
            "epoch 2/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "9m 37s (- 86m 35s) (2 10%) 5.6628\n",
            "epoch 3/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "14m 30s (- 82m 10s) (3 15%) 4.6412\n",
            "epoch 4/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "19m 23s (- 77m 34s) (4 20%) 3.8930\n",
            "epoch 5/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "24m 17s (- 72m 51s) (5 25%) 3.3482\n",
            "epoch 6/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "29m 11s (- 68m 6s) (6 30%) 2.9500\n",
            "epoch 7/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "34m 5s (- 63m 18s) (7 35%) 2.6452\n",
            "epoch 8/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "38m 59s (- 58m 29s) (8 40%) 2.3601\n",
            "epoch 9/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "43m 53s (- 53m 39s) (9 45%) 2.2798\n",
            "epoch 10/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "48m 47s (- 48m 47s) (10 50%) 1.9971\n",
            "epoch 11/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "53m 41s (- 43m 55s) (11 55%) 1.8279\n",
            "epoch 12/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "58m 35s (- 39m 3s) (12 60%) 1.7858\n",
            "epoch 13/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "63m 30s (- 34m 11s) (13 65%) 1.6999\n",
            "epoch 14/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "68m 25s (- 29m 19s) (14 70%) 1.5673\n",
            "epoch 15/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "73m 19s (- 24m 26s) (15 75%) 1.5701\n",
            "epoch 16/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "78m 13s (- 19m 33s) (16 80%) 1.4802\n",
            "epoch 17/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "83m 8s (- 14m 40s) (17 85%) 1.3954\n",
            "epoch 18/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "88m 2s (- 9m 46s) (18 90%) 1.2659\n",
            "epoch 19/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "92m 57s (- 4m 53s) (19 95%) 1.2971\n",
            "epoch 20/20\n",
            "    running batch 100 of 1061\n",
            "    running batch 200 of 1061\n",
            "    running batch 300 of 1061\n",
            "    running batch 400 of 1061\n",
            "    running batch 500 of 1061\n",
            "    running batch 600 of 1061\n",
            "    running batch 700 of 1061\n",
            "    running batch 800 of 1061\n",
            "    running batch 900 of 1061\n",
            "    running batch 1000 of 1061\n",
            "97m 51s (- 0m 0s) (20 100%) 1.1862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K44QRGgOfMQH"
      },
      "source": [
        "def clean_sentence(sentence):\n",
        "    '''\n",
        "      Function to remove the punctuation from the test sentence\n",
        "    '''\n",
        "    punctuations=list(string.punctuation)\n",
        "    cleaned=\"\"\n",
        "    for letter in sentence:\n",
        "        if letter=='<' or letter=='>' or letter not in punctuations:\n",
        "            cleaned+=letter\n",
        "    return cleaned\n",
        "\n",
        "def predict_translation(model,sentence,device,max_length=MAX_LENGTH):\n",
        "    '''\n",
        "      function will return the translation predicted by the trained model for each sentence\n",
        "    '''\n",
        "    sentence=clean_sentence(sentence)\n",
        "    tokens=sentence.split(\" \")\n",
        "    indexes=[]\n",
        "    for token in tokens:\n",
        "        if token in eng_vocab.word_2_index:\n",
        "            indexes.append(eng_vocab.word_2_index[token])\n",
        "        else:\n",
        "            indexes.append(eng_vocab.word_2_index[\"<UKN>\"])\n",
        "    indexes=indexes[:MAX_LENGTH+2]  # model is trained on MAX_LENGTH sentences only so it expects sentences of this length only\n",
        "    tensor_of_sentence=torch.LongTensor(indexes).unsqueeze(1).to(device)\n",
        "    outputs=[0]   #adding <SOS> in the beginning of output\n",
        "    for _ in range(max_length):\n",
        "        target_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "        with torch.no_grad():\n",
        "            output=model(tensor_of_sentence,target_tensor)\n",
        "        pred=output.argmax(2)[-1, :].item()\n",
        "\n",
        "        outputs.append(pred)\n",
        "\n",
        "        if hindi_vocab.index_2_word[pred] ==\"<EOS>\":\n",
        "            break\n",
        "\n",
        "    final=[]\n",
        "\n",
        "    for i in outputs:\n",
        "        if i == \"<PAD>\":\n",
        "            break\n",
        "        final.append(i)\n",
        "\n",
        "    final = [hindi_vocab.index_2_word[idx] for idx in final if idx not in [0,1,2]]\n",
        "    translated=\" \".join(final)\n",
        "    return translated"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateEnglishSentence(sentence):\n",
        "    extra_tokens = MAX_LENGTH-len(sentence.strip().split(\" \"))\n",
        "    cleanedSentence = sentence.split(\" \")\n",
        "    cleanedSentence.insert(0,\"<SOS>\")\n",
        "    cleanedSentence.append(\"<EOS>\")\n",
        "    cleanedSentence = cleanedSentence +[\"<PAD>\"]*(extra_tokens)\n",
        "    return \" \".join(cleanedSentence)\n",
        "\n",
        "\n",
        "def generate_translation_from_english(model , sentence , device):\n",
        "  sentence = generateEnglishSentence(sentence)\n",
        "  return predict_translation(model , sentence , device)\n",
        "\n",
        "generate_translation_from_english(model , \"how are you\" , device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PqSSJCNHS3Bm",
        "outputId": "d0ece741-7ba5-462b-c3e5-e7501c777997"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'आप किस तरह से'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st7xPjpRfvPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef188c86-9f66-403f-db4d-666050855542"
      },
      "source": [
        "# Checking how the model is translating sentences from the train set\n",
        "test_sentences=[pair[1] for pair in pairs[75:150]]\n",
        "actual_sentences=[pair[0] for pair in pairs[75:150]]\n",
        "pred_sentences=[]\n",
        "\n",
        "for idx,i in enumerate(test_sentences):\n",
        "    translated=predict_translation(model,i,device)\n",
        "    print(\"*\"*20)\n",
        "    print(f\"English: {i}\")\n",
        "    print(f\"Actual: {actual_sentences[idx]}\")\n",
        "    print(f\"Predicted: {translated}\")\n",
        "    print(\"*\"*20)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "English: <SOS> survival skills <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> उत्तरजीविता कौशल <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: उत्तरजीविता कौशल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> sociology of culture <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> संस्कृति का समाजशास्‍त्र <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: संस्कृति का समाजशास्‍त्र\n",
            "********************\n",
            "********************\n",
            "English: <SOS> load the last project that was not burned and not saved <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अंतिम परियोजना लोड करें जो नहीं लिखी और नहीं सहेजी गई थी <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: फ़ाइल को पता नहीं दिया गया था और जो कुछ नहीं था\n",
            "********************\n",
            "********************\n",
            "English: <SOS> hand driven machine <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> हस्तचालित मशीन <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: हस्तचालित मशीन\n",
            "********************\n",
            "********************\n",
            "English: <SOS> aimless <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> उठल्लू <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: उठल्लू\n",
            "********************\n",
            "********************\n",
            "English: <SOS> it is indeed an evil halt and an evil abode <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> निश्चय ही वह जगह ठहरने की दृष्टि से भी बुरी है और स्थान की दृष्टि से भी <EOS> <PAD> <PAD> <PAD>\n",
            "Predicted: बेशक ये क़ुरान क़ौले फ़ैसल है और ये अवगुण अच्छाईयां और निश्चय ही बुरा ठिकाना बुरा ठिकाना है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> go for regular walks in groups and socialise <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> लोगों के साथ मिलकर सैर के लिए जाएं और सामाजिक बनें। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: जल्द और अपने चौपायों और के साथ जाओ\n",
            "********************\n",
            "********************\n",
            "English: <SOS> now jeevan dutt could speak out to the world without hesitation and say that it was a fact <EOS> <PAD> <PAD>\n",
            "Actual: <SOS> जीवनदत्त ऊंची आवाज से घोषित कर सकते हैं कि यह सत्य है सत्य है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: जीवनदत्त ऊंची आवाज मिल सकता है और तब हमें उस समय दुनिया में जीत सकता है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> impracticably <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अव्यावहारिक रूपसे <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: अव्यावहारिक रूपसे\n",
            "********************\n",
            "********************\n",
            "English: <SOS> flail <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> चाबुक <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: चाबुक\n",
            "********************\n",
            "********************\n",
            "English: <SOS> ldap servers <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> ldap सर्वर <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: ldap सर्वर\n",
            "********************\n",
            "********************\n",
            "English: <SOS> jakhu hill <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> जाखू हिल <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: जाखू हिल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> rattlepated <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अजान <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: अजान\n",
            "********************\n",
            "********************\n",
            "English: <SOS> mizo language <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> मिज़ो भाषा <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: मिज़ो भाषा\n",
            "********************\n",
            "********************\n",
            "English: <SOS> national social assistance programme nsap <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> राष्ट्रीय सामाजिक सहायता कार्यक्रम एनएसएपी <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: राष्ट्रीय सामाजिक सहायता कार्यक्रम एनएसएपी\n",
            "********************\n",
            "********************\n",
            "English: <SOS> most under developed countries are in national debt <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अधिकतर विकासशील देश राष्ट्रीय ऋण के बोझ तले हैं। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: अधिकतर विकासशील देशों में विकसित हो चुका है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> shreekhand <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> श्रीखंड <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: श्रीखंड\n",
            "********************\n",
            "********************\n",
            "English: <SOS> italian sounds <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> इतालवी ध्वनियाँ <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: इतालवी ध्वनियाँ\n",
            "********************\n",
            "********************\n",
            "English: <SOS> vertical tiles <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> लंबवत टाइल <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: लंबवत टाइल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> final value of the interval <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> y अक्ष पर अंतिम मान <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: पृष्ठ की अंतिम अंतराल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> it was presented to the legislative council in 1856 and was passed in 1860 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> इसे 1856 में विधायी परिषद के समक्ष प्रस्तुत किया गया और1860 में पारित किया गया। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: सन् 1976 में भारत के निर्माण के लिए सन् 1932 में गया।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> and we rescued those who accepted faith and used to fear <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> और हमने उन लोगों को जो ईमान लाए थे और परहेज़गार थे बचा लिया <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: और हमने उन लोगों को बचा लिया जो ईमान लाए और डर रखते है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> bollywood produces about 150  200 movies yearly <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> इस उद्योग में प्रतिवर्शः १५०२०० फिल्में बनती हैं। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: भारत के राष्ट्रपति ने नीलम संजीव रेड्डी को संदर्भित करता है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> there should be a new lesson on new slate <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> नयी कलम से नया सबक लिखो। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: नए विचारों का नए दृष्टिकोण को एक नयी बात करनी होगी।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> we have made mechanical brains almost as sophisticated as our own <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> हमने अत्याधुनिक यांत्रिक दिमाग बनाये है उन्हें भी लगभग हमारे दिमाग की तरह ही तत्वज्ञान है। <EOS> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: हमने अत्याधुनिक यांत्रिक दिमाग लिख रहे हैं अंतः हमारे पास ही सूफ़ीवाद का सृजन होता है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> barroom <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> शराबख़ाना <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: चिड़िया\n",
            "********************\n",
            "********************\n",
            "English: <SOS> what is the reality <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> क्या है वह होकर रहनेवाली <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: क्या सचमुच वास्तविकता को है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> mill hill <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> मिल हिल <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: मिल हिल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> plant <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> स्थापित करना <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: पौधे\n",
            "********************\n",
            "********************\n",
            "English: <SOS> an extreme unbearable pain <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> तेज असहनीय दर्द <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: तेज असहनीय दर्द\n",
            "********************\n",
            "********************\n",
            "English: <SOS> syncing folders <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> फ़ोल्डर का तुल्यकालन कर रहा है <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: फ़ोल्डर का तुल्यकालन कर रहा है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> national voters day <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> राष्ट्रीय मतदाता दिवस <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: राष्ट्रीय मतदाता दिवस\n",
            "********************\n",
            "********************\n",
            "English: <SOS> on the basis of an assessment of the current and evolving macroeconomic situation it has been decided to <EOS> <PAD> <PAD>\n",
            "Actual: <SOS> वर्तमान और उभरती समष्टि आर्थिक स्थिति के आकलन के आधार पर यह निर्णय लिया गया है किः <EOS> <PAD> <PAD> <PAD>\n",
            "Predicted: आधार पर वलयाकार कुंडलियों सहित यह निश्चित रूप से कार्य की समीक्षा होती है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> he hasn t arrived as yet <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> वह अभी तक नहीं पहुँचा। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: वह अभी तक नहीं पहुँचा।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> there were also a few mills in canada brazil and japan <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> कनाडा ब्राजील और जापान में भी कुछ मिलें थीं <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: कनाडा ब्राजील के हमारे पड़ोस में भी थे।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> so if you look at it it actually looks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> तो अगर तुम इसे देखो यह वास्तव में लग रहा है <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: तो अगर तुम देखो देखो तो यह वास्तव में देखो\n",
            "********************\n",
            "********************\n",
            "English: <SOS> chair <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> प्राध्यापकी <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: प्राध्यापकी\n",
            "********************\n",
            "********************\n",
            "English: <SOS> part xi relations between the union and the states 241 kb pdf file that opens in a new window <EOS> <PAD>\n",
            "Actual: <SOS> भाग संघ और राज्यों के बीच संबंध 241 पीडीएफ फाइल जो नई विंडों में खुलती है <EOS> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: राज्य के बीच संबंध में भाग लेने के बीच अनुभाग है के बीच में भाग लेंगे।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> a graph with 2 nodes fully connected has one edge 3 has three   that s a triangle <EOS> <PAD>\n",
            "Actual: <SOS> 2 नोड पूरी तरह से जुड़ा के साथ एक ग्राफ एक एज 3 तीनएक त्रिकोण है कि है <EOS> <PAD> <PAD>\n",
            "Predicted: 2 नोड के साथ एक खंड 2 है क्योंकि वहाँ है जो 3 है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> argentina and brazil fob determine the physical prices <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अर्जेंटीना और ब्राजील एफओबी फिजिकल मूल्यों का निर्धारण करते हैं। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: कालीन और ब्राजील एफओबी फिजिकल मूल्यों का निर्धारण\n",
            "********************\n",
            "********************\n",
            "English: <SOS> wellfavored <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> वसीम <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: वसीम\n",
            "********************\n",
            "********************\n",
            "English: <SOS> endemic goitre is found in high mountain region of himalaya <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> स्थानिक घेघा रोग हिमालय के उच्च पर्वतीय प्रदेशों में पाया जाता है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: स्थानिक घेघा क्षेत्र में स्थित होता है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> supplying <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> विधान <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: बाढ़\n",
            "********************\n",
            "********************\n",
            "English: <SOS> what is your aim screen name <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> आपका aim स्क्रीन नाम क्या है <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: आपका aim स्क्रीन नाम क्या है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> not that uncle ken had any intention of winning <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> ऐसी बात नहीं थी कि केन काका महाराजा से जीतने को लालायित थे। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: नहीं जो घिर कर पाता था।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> their efforts during vande bharat mission and other covid related help to our citizens and other nations is noteworthy <EOS> <PAD>\n",
            "Actual: <SOS> स्‍वामित्‍व योजना के तहत संपत्ति कार्ड के वितरण के शुभारंभ पर प्रधानमंत्री के सम्बोधन का मूल पाठ <EOS> <PAD> <PAD> <PAD>\n",
            "Predicted: स्‍वामित्‍व योजना के दौरान देश के अन्य समस्याओं के हितों को सेवा प्रदान की जानकारी प्राप्त करने के लिए\n",
            "********************\n",
            "********************\n",
            "English: <SOS> betterlooking <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> सलोना <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: सलोना\n",
            "********************\n",
            "********************\n",
            "English: <SOS> veena <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> वीणा <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: वीणा\n",
            "********************\n",
            "********************\n",
            "English: <SOS> but i also want to share another pain with the country today <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> लेकिन मैं आज देश के सामने एक और पीड़ा भी व्‍यक्‍त करना चाहता हूं। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: लेकिन मैं भी एक देश के साथ एक भी अवसर भी जैसी भी मिलती\n",
            "********************\n",
            "********************\n",
            "English: <SOS> x alignment <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> x संरेखण <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: x संरेखण\n",
            "********************\n",
            "********************\n",
            "English: <SOS> responsibility <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> उत्तरदायित्व <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: उत्तरदायित्व\n",
            "********************\n",
            "********************\n",
            "English: <SOS> inheritance occurs through germ cells <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> वंशागति जनन कोशिकाओं के माध्यम से चलती है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: वंशागति जनन कोशिकाएं धन का होता है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> the password for the user id above if any <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> उपयोक्ता id ऊपर के लिए कूटशब्द यदि कोई है <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: उपयोक्ता के लिए कूटशब्द का नाम दिया है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> john roy major <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> जान राय मेजर <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: जान राय मेजर\n",
            "********************\n",
            "********************\n",
            "English: <SOS> but then they turned away from him saying he is tutored mad <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> फिर उन्होंने उसकी ओर से मुँह मोड़ लिया और कहने लगे यह तो एक सिखायापढ़ाया दीवाना है। <EOS> <PAD> <PAD> <PAD>\n",
            "Predicted: किन्तु फिर उसे लगा कि वे सख़्त होकर उसे अकेले छोड़ कर दें\n",
            "********************\n",
            "********************\n",
            "English: <SOS> financial integrity makes way <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> वित्तीय निष्ठा कठिन परिस्थितियों रास्ता बनाती है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: वित्तीय निष्ठा उचित तरीका\n",
            "********************\n",
            "********************\n",
            "English: <SOS> in a democracy nothing sustainable can be achieved without people s support <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> लोकतंत्र में लोगों के समर्थन के बिना स्यायी रुप से कुछ भी हासिल नहीं किया जा सकता। <EOS> <PAD> <PAD> <PAD>\n",
            "Predicted: लोकतंत्र में हमारे श्रमिक भी समर्थन नहीं हो सकती है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> the ethical teaching of sami cannot be better summarised <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> सामी के श्लोकों के नैतिक पहलू की इससे अधिक अच्छी व्याख्या नहीं हो सकती। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: सामी के श्लोकों की प्रतिभा भी नहीं होते।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> copy the selection <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> चयनित प्रतिलिपि करें <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: चयनित प्रतिलिपि करें\n",
            "********************\n",
            "********************\n",
            "English: <SOS> but where are the taliban leaders and their committed cadres <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> लेकिन तालिबान के नेता और समर्पित कार्यकर्ता कहां हैं <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: लेकिन तालिबान और अभिभावकों के लिए लड़ाई में आतंकवादी हरकतों की कड़ी को छोड़ रही है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> and said shall we forsake our deities for the sake of a distracted poet <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> और कहते थे क्या हम एक उन्मादी कवि के लिए अपने उपास्यों को छोड़ दें <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: और कहा हम क्या जाने वाले लोगों ने अपने लोगों को इस्तेमाल से अपने पास से कहा\n",
            "********************\n",
            "********************\n",
            "English: <SOS> ravisher <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> गुल <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: मनोरमा\n",
            "********************\n",
            "********************\n",
            "English: <SOS> deleting files from archive <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> फ़ाइलों को अभिलेख से मिटा रहे <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: फ़ाइलों से मिटा रहा स्वरूप में फ़ाइल\n",
            "********************\n",
            "********************\n",
            "English: <SOS> send  receive mail <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> डाक भेजें और प्राप्त करें <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: डाक भेजें और डाक प्राप्त करें\n",
            "********************\n",
            "********************\n",
            "English: <SOS> this form is literal not in the form of meaning <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> यह वह्य शाब्दिक है अर्थ के रूप में नहीं। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: यह वह्य शाब्दिक है कि तरह की आत्मा है पर नहीं है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> for those of you who wish to walk straight <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> मगर उसी के लिए जो तुममें सीधी राह चले <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: जो तुम्हारे लिए तुम्हारे लिए तुम्हारे लिए कौन है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> please check any problems above and then proceed to the final step <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> ऊपर किसी भी समस्याओं की जाँच करें और तब अंतिम चरण के लिए आगे बढ़ें <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: कृपया किसी को देखो यहाँ से नीचे सुरक्षा के लिए कृपया ध्यान दीजिए\n",
            "********************\n",
            "********************\n",
            "English: <SOS> mental can refer to mind <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> मानसिक मस्तिष्क को दर्शा सकता है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: मानसिक मन का मानसिक मन में मानसिक रूप में सोचने का ध्यान दे सकता है।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> adulthood <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> तरुणावस्था <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: तरुणावस्था\n",
            "********************\n",
            "********************\n",
            "English: <SOS> working capital should be established before the setup of business <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> कारोबार की स्थापना से पूर्व सक्रिय पूँजी सुस्थापित होनी चाहिए। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: चालू अनुसंधान व्यवसाय के समक्ष व्यवसाय के लिए किया जाना चाहिए।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> butane gas in cigarette lighters and refill canisters it is also used as a propellant in any aerosols <EOS> <PAD> <PAD>\n",
            "Actual: <SOS> सॉल्वैंट के आधार वाली गोंदें जैसे कि एवोस्टिक। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: सॉल्वैंट के आधार पर गोंदें जैसे कि एवोस्टिक।\n",
            "********************\n",
            "********************\n",
            "English: <SOS> but gora did not say anything more and walked away with deliberate steps <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> गोरा और कुछ कहे बिना धीरगति से चला गया। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: लेकिन हारान के बाद में आने वाली काल से अधिक नहीं होते\n",
            "********************\n",
            "********************\n",
            "English: <SOS> i could not follow let alone taking interest in the professors lectures <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> अध्यापकोंके व्याख्यानोंमें न तो मुझे रस आता और न मैं उन्हें समझ पाता था। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: अध्यापकोंके व्याख्यानोंमें न तो मैं नहीं जा सकता हूं कि दुनिया में शांति\n",
            "********************\n",
            "********************\n",
            "English: <SOS> are there triggering factors <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> क्या इसके कोई अतिशीघ्र प्रेरक उपादान होते हैं <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: आधारभूत नियम है\n",
            "********************\n",
            "********************\n",
            "English: <SOS> united states is on the north american continent and is a united democracy <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Actual: <SOS> संयुक्त राज्य अमेरिका उत्तर अमेरिकी महाद्वीप पर स्थित एक संघीय गणतंत्र है। <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Predicted: संयुक्त राज्य भूगर्भ स्थित लोगों को संयुक्त राज्य है।\n",
            "********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNWk_8ynnPAA"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}